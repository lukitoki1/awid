{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Parameters \"\"\"\n",
    "# α = 0.001; ITERS = 250; λ = 0.005;\n",
    "# range = -0.01:0.001:0.01\n",
    "# HIDDEN_SIZE = 2\n",
    "# W1 = rand(range, 2, HIDDEN_SIZE )\n",
    "# b1 = zeros((1, HIDDEN_SIZE));\n",
    "# W2 = rand(range, HIDDEN_SIZE, 1 )\n",
    "# b2 = 0.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_LogRegNN_GD( W1, b1, W2, b2, ITERS, α, λ, Y; max_error=0 )\n",
    "    \n",
    "    loss_acc = zeros(ITERS) # Loss per iteration\n",
    "    W2_acc = zeros(2, ITERS) # History of weights changes\n",
    "    Ŷ = 0 # Final prediction\n",
    "    \n",
    "    for i in 1:ITERS        \n",
    "        W2_acc[:,i] = W2\n",
    "    \n",
    "        A1, A2 = forward( X, W1, b1, W2, b2 )\n",
    "        Ŷ = A2\n",
    "        \n",
    "        data_loss = loss_function( Y, Ŷ )\n",
    "        reg_loss = regularization_loss( W1, W2, λ )\n",
    "        loss_acc[i] = data_loss + reg_loss\n",
    "        \n",
    "        if loss_acc[i] < max_error\n",
    "            # println( \"GD stopped after $i iteration\" )\n",
    "            return loss_acc, Int.(round.(Ŷ)), W1, b1, W2, b2, W2_acc, i\n",
    "        end\n",
    "        \n",
    "        new_W1, new_b1, new_W2, new_b2 = gradient_descent(\n",
    "            A1, A2, W1, b1, W2, b2, α, λ, Y\n",
    "        )\n",
    "        W1 = new_W1; b1 = new_b1; W2 = new_W2; b2 = new_b2 \n",
    "    end\n",
    "    \n",
    "    pred_class = Int.(round.(Ŷ))\n",
    "    return loss_acc, pred_class, W1, b1, W2, b2, W2_acc, ITERS\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function dot( X, W, b )\n",
    "    return X * W .+ b\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "function σ( z )\n",
    "    return 1 / (1 + exp(-z))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "function forward( X, W1, b1, W2, b2 )\n",
    "    Z1 = dot( X, W1, b1 ) .* 1000 # Scaling for Iris Dataset\n",
    "    A1 = σ.( Z1 ) # ReLU can be used here instead\n",
    "    Z2 = dot( A1, W2, b2 ) * 1000\n",
    "    A2 = σ.(Z2)\n",
    "    return A1, A2\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss_function( Y, Ŷ )\n",
    "    losses = [ (y * log(ŷ) + (1-y) * log(1-ŷ)) for (y, ŷ) in zip(Y, Ŷ) ]\n",
    "    M = length(Ŷ)\n",
    "    avg_loss = -(sum(losses) / M)\n",
    "    return avg_loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function regularization_loss( W1, W2, λ )\n",
    "    reg_loss = 0.5*λ*sum(W1.^2) + 0.5*λ*sum(W2.^2)\n",
    "    return reg_loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "function gradient_descent( A1, A2, W1, b1, W2, b2, α, λ, Y )\n",
    "    \n",
    "    # Derivatives calculation\n",
    "    ∂W1, ∂b1, ∂W2, ∂b2 = backprop( A1, A2, W2, Y )\n",
    "    \n",
    "    # Regularization\n",
    "    ∂W1 .+= λ * W1\n",
    "    ∂W2 .+= λ * W2\n",
    "    \n",
    "    # Weights update\n",
    "    new_W1 = W1 - α * ∂W1\n",
    "    new_b1 = b1 .- α * ∂b1\n",
    "    \n",
    "    new_W2 = W2 - α * ∂W2\n",
    "    new_b2 = b2 - α * ∂b2\n",
    "    \n",
    "    return new_W1, new_b1, new_W2, new_b2\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "function backprop( A1, A2, W2, Y )\n",
    "    \n",
    "    M = length(Y)\n",
    "    \n",
    "    ∂Z2 = A2 .- Y\n",
    "    ∂W2 = (transpose(A1) * ∂Z2) ./ M\n",
    "    ∂b2 = sum(∂Z2) ./ M\n",
    "\n",
    "    ∂A1 = W2 * transpose(∂Z2)\n",
    "    ∂Z1 = transpose(A1 .- Y)\n",
    "    \n",
    "    ∂W1 = (∂Z1 * X) ./ M\n",
    "    ∂W1 = transpose(∂W1)\n",
    "    ∂b1 = sum(∂Z1, dims=2) ./ M\n",
    "    ∂b1 = transpose(∂b1);\n",
    "    \n",
    "    return ∂W1, ∂b1, ∂W2, ∂b2\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "function cost_for_W2( Θ1, Θ2, Y )\n",
    "    W2 = [Θ1, Θ2]\n",
    "    A1, Ŷ = forward( X, W1, b1, W2, b2 )\n",
    "    loss = loss_function( Y, Ŷ )\n",
    "    return loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to minimize. Input: flat vector, Output: number\n",
    "function forward_loss( flat )\n",
    "    W2, W1, b2, b1 = roughen( flat )\n",
    "    A1, A2 = forward( X, W1, b1, W2, b2 )\n",
    "    Ŷ = A2\n",
    "    return loss_function( Y, Ŷ )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "function round_weights( flat )\n",
    "    return [round(v, digits=8) for v in flat]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "function flatten( weights_list ) # Dict() to 1D Array\n",
    "    line = []\n",
    "    for v in weights_list\n",
    "        line = [ line...; (v...)... ]\n",
    "    end\n",
    "    return round_weights( line )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "function roughen( flat ) # hard-coded counterpart of flatten\n",
    "    W2 = reshape([flat[1] ; flat[2] ], (2,1))\n",
    "    W1 = [ flat[3] flat[5]; flat[4] flat[6] ]\n",
    "    b1 = [ flat[8] flat[9] ]\n",
    "    b2 = flat[7]\n",
    "    return W2, W1, b2, b1\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "function forward_loss_gradient( Θ )\n",
    "    W2, W1, b2, b1 = roughen( Θ )\n",
    "    A1, A2 = forward( X, W1, b1, W2, b2 )\n",
    "    grad = [backprop( A1, A2, W2, Y )]\n",
    "    return flatten(grad)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function limit_weights( new_Θ, Θ )\n",
    "#     min_weight_value = 10e-4\n",
    "#     for i in 1:length(Θ)\n",
    "#         if (new_Θ[i] < min_weight_value) new_Θ[i] = Θ[i] end\n",
    "#     end\n",
    "#     return round_weights( new_Θ )\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_LogRegNN_BFGS( weights, ITERS; max_error=0, v=true )\n",
    "    \n",
    "    # DIM = 9\n",
    "    DIM = HIDDEN_SIZE * 2 + HIDDEN_SIZE + HIDDEN_SIZE + 1\n",
    "    Q = Matrix(1.0I, DIM, DIM)    \n",
    "    losses = zeros(1, ITERS)\n",
    "    \n",
    "    for i in 1:ITERS\n",
    "        if v==true println(\"\\n==== Iteration \", i, \" ====\") end\n",
    "        \n",
    "        # Forward pass\n",
    "        W1, W2 = weights[\"W1\"][end], weights[\"W2\"][end]\n",
    "        b1, b2 = weights[\"b1\"][end], weights[\"b2\"][end]\n",
    "        A1, A2 = forward( X, W1, b1, W2, b2 )\n",
    "        Ŷ = A2\n",
    "        losses[i] = loss_function( Y, Ŷ )\n",
    "        \n",
    "        if losses[i] < max_error\n",
    "            # println( \"BFGS stopped after $i iteration\" )\n",
    "            return losses, i\n",
    "        end\n",
    "        \n",
    "        # Flattening\n",
    "        Θ = flatten( [W2, W1, b2, b1] )\n",
    "        ∇f = forward_loss_gradient\n",
    "\n",
    "        # Optimizing using BFGS\n",
    "        new_flat, Q = BFGS( forward_loss, ∇f, Θ, Q )\n",
    "        if v==true println(Q) end\n",
    "        # new_weights = roughen( limit_weights(new_flat, Θ) )\n",
    "        new_weights = roughen( round_weights(new_flat) )\n",
    "        \n",
    "        if v==true println( \"Iteration \", i, \" finished. Weights:\" ) end\n",
    "        for (key, new_value) in zip( keys(weights), new_weights ) \n",
    "            if v==true println( key, \" \", new_value ) end\n",
    "            push!( weights[ key ], new_value )            \n",
    "        end\n",
    "\n",
    "    end\n",
    "    \n",
    "    return losses, ITERS\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_LogRegNN_LBFGS( weights, ITERS, m; max_error=0, v=true )\n",
    "    \n",
    "    # DIM = 9\n",
    "    DIM = HIDDEN_SIZE * 2 + HIDDEN_SIZE + HIDDEN_SIZE + 1 \n",
    "    losses = zeros(1, ITERS)\n",
    "    δs, γs, qs = [], [], []\n",
    "    \n",
    "    for i in 1:ITERS\n",
    "        if v==true println(\"\\n==== Iteration \", i, \" ====\") end\n",
    "        \n",
    "        # Forward pass\n",
    "        W1, W2 = weights[\"W1\"][end], weights[\"W2\"][end]\n",
    "        b1, b2 = weights[\"b1\"][end], weights[\"b2\"][end]\n",
    "        A1, A2 = forward( X, W1, b1, W2, b2 )\n",
    "        Ŷ = A2\n",
    "        losses[i] = loss_function( Y, Ŷ )\n",
    "        \n",
    "        if losses[i] < max_error return losses, i end\n",
    "        \n",
    "        # Flattening\n",
    "        Θ = flatten( [W2, W1, b2, b1] )\n",
    "        ∇f = forward_loss_gradient\n",
    "\n",
    "        # Optimizing using BFGS\n",
    "        new_flat, δs, γs, qs = LBFGS( forward_loss, ∇f, Θ, m, δs, γs, qs )\n",
    "\n",
    "        new_weights = roughen( round_weights(new_flat) )\n",
    "        \n",
    "        if v==true println( \"Iteration \", i, \" finished. Weights:\" ) end\n",
    "        for (key, new_value) in zip( keys(weights), new_weights ) \n",
    "            if v==true println( key, \" \", new_value ) end\n",
    "            push!( weights[ key ], new_value )            \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return losses, ITERS\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
